{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "I0ZK08o00bi5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from utils import prepare_data, encode_and_save\n",
    "from model import BModel, GModel\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "51KV58vY3Il9"
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.dataset = \"mnist\" # mnist | fmnist | cifar | isolet | ucihar\n",
    "args.model = \"rff-gvsa\" # rff-hdc linear-hdc rff-gvsa\n",
    "args.dim = 10000\n",
    "args.gamma = 0.8\n",
    "args.gorder = 16\n",
    "args.lr = 0.01\n",
    "args.epoch = 10\n",
    "args.seed = 42\n",
    "args.data_dir = './encoded_data'\n",
    "args.raw_data_dir = \"./dataset\"\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lgVv0D5lKVTE"
   },
   "outputs": [],
   "source": [
    "if \"hdc\" in args.model:\n",
    "   args.gorder = 2\n",
    "   print(\"Use binary HDC with random fourier features, ignoring gorder, set to 2.\")\n",
    "args.data_dir = f\"{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeXrjVjeHnKh",
    "outputId": "58a21b99-0ee4-442d-bfa4-a3d18749e9a1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  os.makedirs(args.data_dir)\n",
    "except FileExistsError:\n",
    "  print(\"Encoded data folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nhrrQL76IMgt",
    "outputId": "99df19fe-5296-445a-e382-d69d43789ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./dataset\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:12<00:00, 763140.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./dataset\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./dataset\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 125593.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./dataset\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./dataset\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:03<00:00, 440626.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./dataset\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./dataset\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2270623.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./dataset\\MNIST\\raw\n",
      "\n",
      "# of channels of data 1\n",
      "# of training samples and test samples 60000 10000\n",
      "Encoding with random fourier features encoder.\n",
      "the threshold to discretize fourier features to group elements tensor([-1.5409, -1.1554, -0.8911, -0.6775, -0.4909, -0.3200, -0.1580,  0.0000,\n",
      "         0.1580,  0.3200,  0.4909,  0.6775,  0.8911,  1.1554,  1.5409])\n",
      "Encoded pixels to hypervectors with size:  torch.Size([256, 10000])\n",
      "Encoding training data...\n",
      "Start encoding data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mencode_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\YOUSSEF\\Documents\\GitHub\\Hyperdimensional-Computing\\utils.py:133\u001b[0m, in \u001b[0;36mencode_and_save\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    130\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(mem, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/item_mem.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m train_hd, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_data_extract_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(train_hd, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train_hd.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    135\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(y_train, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/y_train.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\YOUSSEF\\Documents\\GitHub\\Hyperdimensional-Computing\\encoder.py:197\u001b[0m, in \u001b[0;36mRandomFourierEncoder.encode_data_extract_labels\u001b[1;34m(self, datast)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch_img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[0;32m    194\u001b[0m     num_imgs \u001b[38;5;241m=\u001b[39m batch_img[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    196\u001b[0m     )  \u001b[38;5;66;03m# in case the last batch is not equal to batch_size\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m     rv[i \u001b[38;5;241m*\u001b[39m batch_size : i \u001b[38;5;241m*\u001b[39m batch_size \u001b[38;5;241m+\u001b[39m num_imgs] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_one_img\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_img\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     labels[i \u001b[38;5;241m*\u001b[39m batch_size : i \u001b[38;5;241m*\u001b[39m batch_size \u001b[38;5;241m+\u001b[39m num_imgs] \u001b[38;5;241m=\u001b[39m batch_img[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m99\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\YOUSSEF\\Documents\\GitHub\\Hyperdimensional-Computing\\encoder.py:157\u001b[0m, in \u001b[0;36mRandomFourierEncoder.encode_one_img\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    153\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m    154\u001b[0m bs, channels, num_pixels \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    155\u001b[0m rv \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_mem\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m--> 157\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_pixels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    159\u001b[0m )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# rv shape now should be [num_pixels, channels, bs, hyperD]\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_pixels):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# for each pixel, shift along hyperD dimension\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encode_and_save(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRUMqPrJHuMQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tpdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
